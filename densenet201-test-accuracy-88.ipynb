{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3044546,"sourceType":"datasetVersion","datasetId":1864500}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n        \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-22T22:20:56.353918Z","iopub.execute_input":"2024-06-22T22:20:56.354581Z","iopub.status.idle":"2024-06-22T22:20:56.379785Z","shell.execute_reply.started":"2024-06-22T22:20:56.354492Z","shell.execute_reply":"2024-06-22T22:20:56.379198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check GPU  (I got a Tesla P100 today)\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-06-22T22:21:04.694811Z","iopub.execute_input":"2024-06-22T22:21:04.695089Z","iopub.status.idle":"2024-06-22T22:21:05.678756Z","shell.execute_reply.started":"2024-06-22T22:21:04.695058Z","shell.execute_reply":"2024-06-22T22:21:05.678010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"execution":{"iopub.status.busy":"2024-06-22T22:21:10.611872Z","iopub.execute_input":"2024-06-22T22:21:10.612161Z","iopub.status.idle":"2024-06-22T22:21:16.156159Z","shell.execute_reply.started":"2024-06-22T22:21:10.612130Z","shell.execute_reply":"2024-06-22T22:21:16.155508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# simply show a picture\nplt.figure(figsize= (10, 10))\nimg = mpimg.imread(\"../input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Normal/test_0_9774.jpeg\")\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T22:21:19.714630Z","iopub.execute_input":"2024-06-22T22:21:19.715443Z","iopub.status.idle":"2024-06-22T22:21:20.426869Z","shell.execute_reply.started":"2024-06-22T22:21:19.715406Z","shell.execute_reply":"2024-06-22T22:21:20.426116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ImageDataGenerator (only can adjust on training data)\ntraingen = ImageDataGenerator(rescale= 1./255,\n                             width_shift_range=0.2 , \n                             height_shift_range=0.2 ,\n                             zoom_range=0.2)\nvalgen = ImageDataGenerator(rescale= 1./255)\ntestgen = ImageDataGenerator(rescale= 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T10:18:04.14192Z","iopub.execute_input":"2022-03-18T10:18:04.142176Z","iopub.status.idle":"2022-03-18T10:18:04.147579Z","shell.execute_reply.started":"2022-03-18T10:18:04.142147Z","shell.execute_reply":"2022-03-18T10:18:04.146551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flow_from_directory\ntrain_it = traingen.flow_from_directory(\"../input/lungs-disease-dataset-4-types/Lung Disease Dataset/train\", target_size = (224, 224))\nval_it = traingen.flow_from_directory(\"../input/lungs-disease-dataset-4-types/Lung Disease Dataset/val\", target_size = (224, 224))\ntest_it = traingen.flow_from_directory(\"../input/lungs-disease-dataset-4-types/Lung Disease Dataset/test\", target_size = (224, 224))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T10:18:34.107237Z","iopub.execute_input":"2022-03-18T10:18:34.107514Z","iopub.status.idle":"2022-03-18T10:18:35.689228Z","shell.execute_reply.started":"2022-03-18T10:18:34.107467Z","shell.execute_reply":"2022-03-18T10:18:35.688524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the picture after ImageDataGenerator\nplt.figure()\nplt.imshow(next(train_it)[0][0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T22:21:31.688968Z","iopub.execute_input":"2024-06-22T22:21:31.689257Z","iopub.status.idle":"2024-06-22T22:21:32.007442Z","shell.execute_reply.started":"2024-06-22T22:21:31.689215Z","shell.execute_reply":"2024-06-22T22:21:32.006413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\n# Data augmentation\ntraingen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    shear_range=0.2,\n    brightness_range=[0.8, 1.2],\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\nvalgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\ntestgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\n# Data generators\ntrain_it = traingen.flow_from_directory(\"/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train\", target_size=(224, 224), batch_size=32, class_mode='categorical')\nval_it = valgen.flow_from_directory(\"/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/val\", target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False)\ntest_it = testgen.flow_from_directory(\"/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/test\", target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False)\n\n# Load the pre-trained DenseNet201 model\nbase_model = tf.keras.applications.DenseNet201(input_shape=(224, 224, 3),\n                                               include_top=False,\n                                               weights='imagenet')\n\n# Phase 1: Train custom layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = layers.GlobalAveragePooling2D()(base_model.output)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(5, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6),\n    tf.keras.callbacks.ModelCheckpoint(\"fin_{epoch}_model.keras\", monitor=\"val_accuracy\", save_best_only=True, verbose=1, mode=\"auto\")\n]\n\nhistory_phase1 = model.fit(\n    train_it,\n    steps_per_epoch=train_it.samples // train_it.batch_size - 1,\n    validation_data=val_it,\n    validation_steps=val_it.samples // val_it.batch_size - 1,\n    epochs=10,\n    callbacks=callbacks\n)\n\n# Phase 2: Fine-tune the entire model\nfor layer in base_model.layers:\n    layer.trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory_phase2 = model.fit(\n    train_it,\n    steps_per_epoch=train_it.samples // train_it.batch_size - 1,\n    validation_data=val_it,\n    validation_steps=val_it.samples // val_it.batch_size - 1,\n    epochs=20,\n    callbacks=callbacks\n)\n\n# Evaluate the model on the training set\ntrain_loss, train_accuracy = model.evaluate(train_it, steps=train_it.samples // train_it.batch_size, verbose=1)\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")\n\n# Evaluate the model on the validation set\nval_loss, val_accuracy = model.evaluate(val_it, steps=val_it.samples // val_it.batch_size, verbose=1)\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_it, steps=test_it.samples // test_it.batch_size, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T22:21:50.081685Z","iopub.execute_input":"2024-06-22T22:21:50.081984Z","iopub.status.idle":"2024-06-22T23:13:25.766879Z","shell.execute_reply.started":"2024-06-22T22:21:50.081952Z","shell.execute_reply":"2024-06-22T23:13:25.766114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine history from both phases\ndef combine_history(history1, history2):\n    history = {}\n    for key in history1.history.keys():\n        history[key] = history1.history[key] + history2.history[key]\n    return history\n\ncombined_history = combine_history(history_phase1, history_phase2)\n\n# Plot training & validation accuracy values\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(combined_history['accuracy'])\nplt.plot(combined_history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(combined_history['loss'])\nplt.plot(combined_history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T23:24:30.151491Z","iopub.execute_input":"2024-06-22T23:24:30.151891Z","iopub.status.idle":"2024-06-22T23:24:30.453076Z","shell.execute_reply.started":"2024-06-22T23:24:30.151855Z","shell.execute_reply":"2024-06-22T23:24:30.452315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nmodel = model\n\n# Assuming your model and data generators are defined as follows:\n# model = your_trained_model\n# validation_generator = your_validation_data_generator\n\n# Step 1: Generate predictions\npredictions = model.predict(test_it)\npredicted_classes = np.argmax(predictions, axis=1)\n\n# Step 2: Get true labels\ntrue_classes = test_it.classes\n\n# Step 3: Get class names\nclass_labels = list(test_it.class_indices.keys())\n\n# Step 4: Calculate the confusion matrix using TensorFlow\nconf_matrix = tf.math.confusion_matrix(true_classes, predicted_classes).numpy()\n\n# Step 5: Calculate accuracy using TensorFlow\naccuracy = tf.keras.metrics.Accuracy()\naccuracy.update_state(true_classes, predicted_classes)\naccuracy_value = accuracy.result().numpy()\n\n# Step 6: Plot the confusion matrix with class names and accuracy\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\n\n# Add accuracy text\nplt.text(0, -0.3, f'Accuracy of Model: {accuracy_value:.2f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, color='red')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T23:31:52.102063Z","iopub.execute_input":"2024-06-22T23:31:52.102370Z","iopub.status.idle":"2024-06-22T23:32:17.315260Z","shell.execute_reply.started":"2024-06-22T23:31:52.102338Z","shell.execute_reply":"2024-06-22T23:32:17.314540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy, F1 score, precision, and recall\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\naccuracy = accuracy_score(true_classes, predicted_classes)\nf1 = f1_score(true_classes, predicted_classes, average='weighted')\nprecision = precision_score(true_classes, predicted_classes, average='weighted')\nrecall = recall_score(true_classes, predicted_classes, average='weighted')\n\n# Print the metrics\nprint(f'Accuracy: {accuracy}')\nprint(f'F1 Score: {f1}')\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')","metadata":{"execution":{"iopub.status.busy":"2024-06-22T23:34:26.227800Z","iopub.execute_input":"2024-06-22T23:34:26.228611Z","iopub.status.idle":"2024-06-22T23:34:26.242526Z","shell.execute_reply.started":"2024-06-22T23:34:26.228567Z","shell.execute_reply":"2024-06-22T23:34:26.241603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\n# Load the pre-trained DenseNet201 model\nbase_model = tf.keras.applications.DenseNet201(input_shape=(224, 224, 3),\n                                                   include_top=False,\n                                                   weights='imagenet')\n\n# Lock the layers of the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add custom layers on top of the base model\n#x = layers.Flatten()(base_model.output)\nx = layers.GlobalAveragePooling2D()(base_model.output)  # Using GlobalAveragePooling2D instead of Flatten\nx = layers.Dropout(0.1)(x)\nx = layers.Dense(512, activation='relu')(x)\n#x = layers.Dense(256, activation='relu')(x)\nx = layers.BatchNormalization()(x)  # Add Batch Normalization\nx = layers.Dense(5, activation='softmax')(x)\n\n# Create the final model\nmodel2 = Model(inputs=base_model.input, outputs=x)\n\n# Compile the model\nmodel2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),  # Set a lower learning rate\n               loss='categorical_crossentropy',\n               metrics=['accuracy'])\n\n\n# Callbacks\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6),\n    tf.keras.callbacks.ModelCheckpoint(\"fin_{epoch}_model.keras\", monitor=\"val_accuracy\", save_best_only= True, verbose=1,mode=\"auto\")\n]\n\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T23:23:17.389123Z","iopub.execute_input":"2024-06-22T23:23:17.389347Z","iopub.status.idle":"2024-06-22T23:23:22.448320Z","shell.execute_reply.started":"2024-06-22T23:23:17.389322Z","shell.execute_reply":"2024-06-22T23:23:22.447549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Earlystop\n> This time I forget to use earlystop. Maybe I need to use it next time (because loss and acc don't change at finall)","metadata":{}},{"cell_type":"code","source":"\n#model2.fit(train_it, validation_data= val_it, epochs=100, callbacks= callbacks, steps_per_epoch=60, validation_steps=5)\n# Train the model\n\nhistory = model2.fit(\n    train_it,\n    steps_per_epoch=train_it.samples // train_it.batch_size - 1,\n    validation_data=val_it,\n    validation_steps=val_it.samples // val_it.batch_size - 1,\n    epochs=20,  # You can increase the number of epochs for more training\n    callbacks=callbacks\n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T10:19:41.821646Z","iopub.execute_input":"2022-03-18T10:19:41.821918Z","iopub.status.idle":"2022-03-18T12:20:08.812154Z","shell.execute_reply.started":"2022-03-18T10:19:41.821889Z","shell.execute_reply":"2022-03-18T12:20:08.811343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dense = keras.models.load_model('fin_18_model.keras')\nmodel_dense.evaluate(test_it, steps=1)model_dense = keras.models.load_model('densenet201.hdf5')\nmodel_dense.evaluate(test_it, steps= 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T12:20:08.814079Z","iopub.execute_input":"2022-03-18T12:20:08.814577Z","iopub.status.idle":"2022-03-18T12:20:20.729819Z","shell.execute_reply.started":"2022-03-18T12:20:08.814527Z","shell.execute_reply":"2022-03-18T12:20:20.72913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}